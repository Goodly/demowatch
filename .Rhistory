?switch
### INPUT -> PROCESS -> OUTPUT PIPELINE ###
library(readr)
dir <- readline("Enter the directory for the `df-canonicalization` folder (without quotes):")
setwd(dir)
### INPUT
### load raw data
raw_metadata <- read_csv("data/textthresher/dfcrowd1dh_task.csv")
raw_tua <- read_csv("data/textthresher/DF_Crowd1.0_DataHunt-TUAS.csv")
raw_taskruns <- read_csv("data/textthresher/dfcrowd1dh_task_run.csv")
raw_qs_ans <- read_csv("data/textthresher/dfcrowd1dh-2018-06-21T01.csv")
scheme_qs <- read_csv("data/scheme_q_types.csv")
# source
source("scripts/TUA_processing.R")
source("scripts/date_place_labeller.R")
source("scripts/quiz_processing.R")
source("scripts/question_weights.R")
source("scripts/cluster.R")
source("scripts/cluster_compacter.R")
# date-label TUAs and IDs
labelled_metadata_tua <- label_date(processed_metadata_tua)
# process TUA data
processed_metadata_tua <- tua_processor(raw_metadata, raw_tua, raw_taskruns)
# date-label TUAs and IDs
labelled_metadata_tua <- label_date(processed_metadata_tua)
# process quiz answers
labelled_qs_ans <- quiz_processor(raw_qs_ans, labelled_metadata_tua)
# cluster and collapse
weights <- question_weighter(scheme_qs, labelled_qs_ans)
canonicalized_features <- data.frame()
for (id in unique(labelled_qs_ans$ids)) {
cluster_tbl <- check_cluster(labelled_qs_ans, id)
print(id)
if (sum(dim(canonicalized_features)) == 0) {
canonicalized_features <- cluster_compacter(cluster_tbl, labelled_qs_ans)
} else {
canonicalized_features <- rbind(canonicalized_features,
cluster_compacter(cluster_tbl, labelled_qs_ans))
}
}
for (id in unique(labelled_qs_ans$ids)) {
cluster_tbl <- check_cluster(labelled_qs_ans, id)
print(id)
if (sum(dim(canonicalized_features)) == 0) {
canonicalized_features <- cluster_compacter(cluster_tbl, labelled_qs_ans, id)
} else {
canonicalized_features <- rbind(canonicalized_features,
cluster_compacter(cluster_tbl, labelled_qs_ans, id))
}
}
check_cluster(labelled_qs_ans, 1)
check_cluster(labelled_qs_ans, 2)
check_cluster(labelled_qs_ans, 3)
check_cluster(labelled_qs_ans, 4)
cluster_tbl <- check_cluster(labelled_qs_ans, 4)
id = 4
### helper function for compacting
compact <- function(df, cluster_num) {
new_df <- df[1,]
for (i in 3:ncol(df)) {
new_df[1,i] <- max(df[,i])
}
new_df <- cbind(new_df[1,3:ncol(df)],
cluster = c(cluster_num))
return(new_df)
}
### filter out feature input for specific ID
id_and_features <- labelled_qs_ans %>% filter(ids == id)
size <- max(cluster_tbl$cluster)
if (size == 1) {
return(id_and_features %>% mutate(cluster = 1))
}
ids_and_features %>% mutate(cluster = 1)
id_and_features %>% mutate(cluster = 1)
return(id_and_features %>% mutate(cluster = 1) %>% slice(1))
id_and_features %>% mutate(cluster = 1) %>% slice(1)
ncol(id_and_features %>% mutate(cluster = 1) %>% slice(1))
canonicalized_features <- data.frame()
for (id in unique(labelled_qs_ans$ids)) {
cluster_tbl <- check_cluster(labelled_qs_ans, id)
print(id)
if (sum(dim(canonicalized_features)) == 0) {
canonicalized_features <- cluster_compacter(cluster_tbl, labelled_qs_ans, id)
} else {
canonicalized_features <- rbind(canonicalized_features,
cluster_compacter(cluster_tbl, labelled_qs_ans, id))
}
}
View(id_and_features)
### filter out feature input for specific ID
id_and_features <- labelled_qs_ans %>% filter(ids == id)
colnames(canonicalized_features)
setdiff(colnames(canonicalized_features), colnames(id_and_features))
colnames(id_and_features)
id = 5
### filter out feature input for specific ID
id_and_features <- labelled_qs_ans %>% filter(ids == id)
View(check_cluster)
cluster_tbl <- check_cluster(labelled_qs_ans, 5)
### helper function for compacting
compact <- function(df, cluster_num) {
new_df <- df[1, ]
for (i in 3:ncol(df)) {
new_df[1, i] <- max(df[, i])
}
new_df <- cbind(new_df[1, 3:ncol(df)],
cluster = c(cluster_num))
return(new_df)
}
### filter out feature input for specific ID
id_and_features <- labelled_qs_ans %>% filter(ids == id)
size <- max(cluster_tbl$cluster)
dataframe_list <- vector("list", size)
for (i in 1:nrow(cluster_tbl)) {
dataframe_list[[cluster_tbl[i, 3]]] <-
rbind(dataframe_list[[cluster_tbl[i, 3]]], id_and_features[i,])
}
for (i in 1:size) {
dataframe_list[[i]] <- compact(dataframe_list[[i]], i)
}
clusters_and_features <- dataframe_list[[1]]
for (i in 2:size) {
clusters_and_features <-
rbind(clusters_and_features, dataframe_list[[i]])
}
View(clusters_and_features)
colnames(clusters_and_features)
id = 4
### filter out feature input for specific ID
id_and_features <- labelled_qs_ans %>% filter(ids == id)
id_and_features %>%
select(-c(task_pybossa_id, contributor_id)) %>%
mutate(cluster = 1) %>% slice(1)
id_and_features %>%
select(-c(task_pybossa_id, contributor_id)) %>%
mutate(cluster = 1) %>% slice(1) %>% colnames()
id_and_features %>%
select(-c(task_pybossa_id, contributor_id)) %>%
mutate(cluster = 1) %>% slice(1) %>% colnames() %>% length()
for (id in unique(labelled_qs_ans$ids)) {
cluster_tbl <- check_cluster(labelled_qs_ans, id)
print(id)
if (sum(dim(canonicalized_features)) == 0) {
canonicalized_features <- cluster_compacter(cluster_tbl, labelled_qs_ans, id)
} else {
canonicalized_features <- rbind(canonicalized_features,
cluster_compacter(cluster_tbl, labelled_qs_ans, id))
}
}
canonicalized_features <- data.frame()
for (id in unique(labelled_qs_ans$ids)) {
cluster_tbl <- check_cluster(labelled_qs_ans, id)
print(id)
if (sum(dim(canonicalized_features)) == 0) {
canonicalized_features <- cluster_compacter(cluster_tbl, labelled_qs_ans, id)
} else {
canonicalized_features <- rbind(canonicalized_features,
cluster_compacter(cluster_tbl, labelled_qs_ans, id))
}
}
View(canonicalized_features)
cluster_compacter(cluster_tbl, labelled_qs_ans, id)
source("scripts/cluster_compacter.R")
for (id in unique(labelled_qs_ans$ids)) {
cluster_tbl <- check_cluster(labelled_qs_ans, id)
print(id)
if (sum(dim(canonicalized_features)) == 0) {
canonicalized_features <- cluster_compacter(cluster_tbl, labelled_qs_ans, id)
} else {
canonicalized_features <- rbind(canonicalized_features,
cluster_compacter(cluster_tbl, labelled_qs_ans, id))
}
}
View(canonicalized_features)
?mutaet
?mutate
canonicalized_features %>% mutate(ids = ids + cluster - 1)
View(canonicalized_features)
canonicalized_features <- data.frame()
for (id in unique(labelled_qs_ans$ids)) {
cluster_tbl <- check_cluster(labelled_qs_ans, id)
print(id)
if (sum(dim(canonicalized_features)) == 0) {
compact_cluster <- cluster_compacter(cluster_tbl, labelled_qs_ans, id) %>%
mutate(ids = cluster)
canonicalized_features <- compact_cluster
} else {
compacted_cluster <- cluster_compacter(cluster_tbl, labelled_qs_ans, id) %>%
mutate(ids = max(canonicalized_features$ids) + cluster - 1)
canonicalized_features <- rbind(canonicalized_features,
compact_cluster)
}
}
View(canonicalized_features)
id = 1
cluster_tbl <- check_cluster(labelled_qs_ans, id)
compact_cluster <- cluster_compacter(cluster_tbl, labelled_qs_ans, id) %>%
mutate(ids = cluster)
View(compact_cluster)
id = 2
cluster_tbl <- check_cluster(labelled_qs_ans, id)
compacted_cluster <- cluster_compacter(cluster_tbl, labelled_qs_ans, id) %>%
mutate(ids = max(canonicalized_features$ids) + cluster - 1)
compacted_cluster <- cluster_compacter(cluster_tbl, labelled_qs_ans, id) %>%
mutate(ids = max(canonicalized_features$ids) + cluster)
View(compact_cluster)
canonicalized_features <- data.frame()
for (id in unique(labelled_qs_ans$ids)) {
cluster_tbl <- check_cluster(labelled_qs_ans, id)
print(id)
if (sum(dim(canonicalized_features)) == 0) {
compact_cluster <- cluster_compacter(cluster_tbl, labelled_qs_ans, id) %>%
mutate(ids = cluster)
canonicalized_features <- compact_cluster
} else {
compact_cluster <- cluster_compacter(cluster_tbl, labelled_qs_ans, id) %>%
mutate(ids = max(canonicalized_features$ids) + cluster)
canonicalized_features <- rbind(canonicalized_features,
compact_cluster)
}
}
View(canonicalized_features)
canonicalized_features <- canonicalized_features %>% select(-cluster)
### OUTPUT
write_csv(canonicalized_features, "data/canonicalized_features.csv")
dir <- readline("Enter the directory for the `df-canonicalization` folder (without quotes):")
setwd(dir)
### INPUT
### load raw data
raw_metadata <- read_csv("data/textthresher/dfcrowd1dh_task.csv")
raw_tua <- read_csv("data/textthresher/DF_Crowd1.0_DataHunt-TUAS.csv")
raw_taskruns <- read_csv("data/textthresher/dfcrowd1dh_task_run.csv")
raw_qs_ans <- read_csv("data/textthresher/dfcrowd1dh-2018-06-21T01.csv")
scheme_qs <- read_csv("data/scheme_q_types.csv")
# source
source("scripts/TUA_processing.R")
source("scripts/date_place_labeller.R")
source("scripts/quiz_processing.R")
source("scripts/question_weights.R")
source("scripts/cluster.R")
source("scripts/cluster_compacter.R")
# process TUA data
processed_metadata_tua <- tua_processor(raw_metadata, raw_tua, raw_taskruns)
# date-label TUAs and IDs
labelled_metadata_tua <- label_date(processed_metadata_tua)
# process quiz answers
labelled_qs_ans <- quiz_processor(raw_qs_ans, labelled_metadata_tua)
# cluster and collapse
weights <- question_weighter(scheme_qs, labelled_qs_ans)
canonicalized_features <- data.frame()
for (id in unique(labelled_qs_ans$ids)) {
cluster_tbl <- check_cluster(labelled_qs_ans, id)
print(id)
if (sum(dim(canonicalized_features)) == 0) {
compact_cluster <- cluster_compacter(cluster_tbl, labelled_qs_ans, id) %>%
mutate(ids = cluster)
canonicalized_features <- compact_cluster
} else {
compact_cluster <- cluster_compacter(cluster_tbl, labelled_qs_ans, id) %>%
mutate(ids = max(canonicalized_features$ids) + cluster)
canonicalized_features <- rbind(canonicalized_features,
compact_cluster)
}
}
canonicalized_features <- canonicalized_features %>% select(-cluster)
View(canonicalized_features)
colnames(labelled_qs_ans)
View(id_and_features)
?hclust
?dist
test_dist <- dist(canonicalized_features[, -295], method = 'binary')
?hclust
test_clust <- hclust(test_dist)
cutree(test_clust, k = 5)
plot(cutree(test_clust, k = 5))
plot(test_clust)
test_clust <- hclust(test_dist, method = 'average')
plot(test_clust)
test_clust <- hclust(test_dist, method = 'median')
plot(test_clust)
?hclust
test_clust <- hclust(test_dist, method = 'ward.D')
plot(test_clust)
test_clust <- hclust(test_dist, method = 'ward.D2')
plot(test_clust)
library(fpc)
cluster.stats
cluster.stats(test_clust)
cluster.stats(cutree(test_clust, k = 5))
cluster.stats(test_dist, cutree(test_clust, k = 5))
?cutree
### INPUT -> PROCESS -> OUTPUT PIPELINE ###
library(readr)
dir <- readline("Enter the directory for the `df-canonicalization` folder (without quotes):")
setwd(dir)
### INPUT
### load raw data
raw_metadata <- read_csv("data/textthresher/dfcrowd1dh_task.csv")
### INPUT
### load raw data
raw_metadata <- read_csv("data/textthresher/dfcrowd1dh_task.csv")
source('C:/Users/Sidney/Desktop/df-canonicalization/pipeline.R', echo=TRUE)
getwd()
source('C:/Users/Sidney/Desktop/df-canonicalization/pipeline.R', echo=TRUE)
View(canonicalized_features)
